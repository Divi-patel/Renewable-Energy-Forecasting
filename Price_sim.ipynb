{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa117998",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e36dcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Initializing Price Simulation...\n",
      "   Found 7 combined files\n",
      "\n",
      "ğŸ’° Price Simulation with Outlier Compression\n",
      "   (Handles extreme prices elegantly)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PRICE SIMULATION WITH OUTLIER COMPRESSION\n",
      "============================================================\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Process all sites at once)\n",
      "1. Blue_Wing_Solar_Energy_Generator\n",
      "2. High_Lonesome_Wind_Power\n",
      "3. Midway_Solar_Farm_III\n",
      "4. Misae_Solar\n",
      "5. Mount_Signal_Solar_Farm_II\n",
      "6. RE_Mustang_LLC\n",
      "7. Stanton_Wind_Energy_LLC\n",
      "============================================================\n",
      "\n",
      "ğŸ“… Auto-detected period: Jul to Jun (12 months)\n",
      "   Starting from current month: Jul\n",
      "\n",
      "============================================================\n",
      "ğŸš€ PROCESSING ALL SITES\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "============================================================\n",
      "Processing: Blue_Wing_Solar_Energy_Generator\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Blue_Wing_Solar_Energy_Generator_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,115\n",
      "   Price range: $-165.83 to $988.58\n",
      "   Negative price hours: 1507 (1.3%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-0.28 to $114.23\n",
      "   Mean: $23.03, P10-P90: $15.88-$31.18\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $23.69, P10-P90: $12.13-$38.01\n",
      "   Based on 10.4 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price/Blue_Wing_Solar_Energy_Generator_price_monthly_timeseries.csv\n",
      "\n",
      "[2/7] Processing High_Lonesome_Wind_Power...\n",
      "\n",
      "============================================================\n",
      "Processing: High_Lonesome_Wind_Power\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: High_Lonesome_Wind_Power_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2010 to 2025 (16 years)\n",
      "   Total data points: 126,010\n",
      "   Price range: $-367.63 to $998.14\n",
      "   Negative price hours: 8702 (6.9%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2010) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-6.38 to $114.20\n",
      "   Mean: $19.71, P10-P90: $0.62-$32.10\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $20.36, P10-P90: $2.04-$38.89\n",
      "   Based on 19.6 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price/High_Lonesome_Wind_Power_price_monthly_timeseries.csv\n",
      "\n",
      "[3/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "============================================================\n",
      "Processing: Midway_Solar_Farm_III\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Midway_Solar_Farm_III_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,401\n",
      "   Price range: $-958.25 to $999.71\n",
      "   Negative price hours: 7632 (6.6%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-86.91 to $122.34\n",
      "   Mean: $31.97, P10-P90: $-6.80-$84.68\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $38.97, P10-P90: $-3.54-$107.71\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price/Midway_Solar_Farm_III_price_monthly_timeseries.csv\n",
      "\n",
      "[4/7] Processing Misae_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing: Misae_Solar\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Misae_Solar_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,097\n",
      "   Price range: $-54.12 to $997.30\n",
      "   Negative price hours: 12534 (10.9%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-3.09 to $114.19\n",
      "   Mean: $20.29, P10-P90: $3.80-$30.37\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $21.70, P10-P90: $5.10-$37.05\n",
      "   Based on 10.2 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price/Misae_Solar_price_monthly_timeseries.csv\n",
      "\n",
      "[5/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "============================================================\n",
      "Processing: Mount_Signal_Solar_Farm_II\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Mount_Signal_Solar_Farm_II_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,401\n",
      "   Price range: $-912.80 to $994.52\n",
      "   Negative price hours: 5488 (4.8%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-8.57 to $122.54\n",
      "   Mean: $29.50, P10-P90: $-1.79-$73.29\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $34.01, P10-P90: $3.46-$80.95\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price/Mount_Signal_Solar_Farm_II_price_monthly_timeseries.csv\n",
      "\n",
      "[6/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing: RE_Mustang_LLC\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: RE_Mustang_LLC_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,385\n",
      "   Price range: $-530.60 to $998.75\n",
      "   Negative price hours: 5511 (4.8%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-6.17 to $167.86\n",
      "   Mean: $41.31, P10-P90: $17.86-$101.24\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $45.62, P10-P90: $20.72-$110.25\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price/RE_Mustang_LLC_price_monthly_timeseries.csv\n",
      "\n",
      "[7/7] Processing Stanton_Wind_Energy_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing: Stanton_Wind_Energy_LLC\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Stanton_Wind_Energy_LLC_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2010 to 2025 (16 years)\n",
      "   Total data points: 126,008\n",
      "   Price range: $-262.90 to $998.44\n",
      "   Negative price hours: 8272 (6.6%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2010) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\n",
      "   âœ“ Created compressed timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-5.39 to $114.20\n",
      "   Mean: $19.45, P10-P90: $-0.86-$32.10\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $27.62, P10-P90: $10.23-$44.38\n",
      "   Based on 19.5 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_hourly_timeseries_compressed.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price/Stanton_Wind_Energy_LLC_price_monthly_timeseries.csv\n",
      "\n",
      "============================================================\n",
      "âœ¨ ALL SITES PROCESSING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   âœ… Successfully processed: 7 sites\n",
      "\n",
      "12-month period: Jul to Jun\n",
      "\n",
      "ğŸ“ Files saved in: Renewable Portfolio LLC/[site_name]/Price/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PriceSimulation:\n",
    "    \"\"\"\n",
    "    Create statistical price profiles with percentile compression for outliers\n",
    "    Handles extreme prices elegantly while preserving their presence in distributions\n",
    "    Compresses values outside P10-P90 range for cleaner statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"\\nğŸ”§ Initializing Price Simulation...\")\n",
    "        \n",
    "        # Define paths - reading from resurety_data folder (UPDATED PATH)\n",
    "        self.data_path = Path('resurety_data')  # Changed from '../resurety_data'\n",
    "        self.base_output_path = Path('Renewable Portfolio LLC')  # New base output path\n",
    "        \n",
    "        # Get available combined files and create mapping\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = []\n",
    "        self.site_file_map = {}  # Map clean site names to actual filenames\n",
    "        \n",
    "        for f in self.available_files:\n",
    "            # Store the full filename (without path)\n",
    "            full_filename = f.name\n",
    "            \n",
    "            # Extract site name by removing '_generation_price_combined.csv'\n",
    "            site_name = f.stem.replace('_generation_price_combined', '')\n",
    "            \n",
    "            # Clean up the site name by removing '_hourly' to avoid redundancy in output files\n",
    "            clean_site_name = site_name.replace('_hourly', '')\n",
    "            \n",
    "            self.available_sites.append(clean_site_name)\n",
    "            # Map the clean name to the actual filename\n",
    "            self.site_file_map[clean_site_name] = full_filename\n",
    "        \n",
    "        print(f\"   Found {len(self.available_files)} combined files\")\n",
    "        \n",
    "        # Define percentiles for FULL distribution (including compressed outliers)\n",
    "        self.full_percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        \n",
    "        # Define compression thresholds (P10 and P90 for compression)\n",
    "        self.compression_lower = 10\n",
    "        self.compression_upper = 90\n",
    "        \n",
    "        # Define thresholds for extreme event tracking\n",
    "        self.negative_threshold = 0\n",
    "        self.spike_threshold = 100\n",
    "        self.extreme_spike_threshold = 200\n",
    "        \n",
    "        # Month names for labeling\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with option for all sites\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PRICE SIMULATION WITH OUTLIER COMPRESSION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"âŒ No combined generation-price files found in resurety_data!\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(\"0. ALL SITES (Process all sites at once)\")\n",
    "        for i, site in enumerate(self.available_sites):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\nğŸ’° Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES'\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(self.available_sites):\n",
    "                        return self.available_sites[idx]\n",
    "                    else:\n",
    "                        print(\"âŒ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"âŒ Please enter a valid number!\")\n",
    "    \n",
    "    def get_automatic_month_range(self):\n",
    "        \"\"\"\n",
    "        Automatically determine month range: current month to 11 months later\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        # Use current month as start\n",
    "        start_month = current_month\n",
    "        \n",
    "        # End month is one month before start month (12 month cycle)\n",
    "        if start_month == 1:\n",
    "            end_month = 12\n",
    "        else:\n",
    "            end_month = start_month - 1\n",
    "        \n",
    "        print(f\"\\nğŸ“… Auto-detected period: {self.month_names[start_month]} to {self.month_names[end_month]} (12 months)\")\n",
    "        print(f\"   Starting from current month: {self.month_names[current_month]}\")\n",
    "        \n",
    "        return start_month, end_month\n",
    "    \n",
    "    def get_months_in_range(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Get list of months in range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        if start_month <= end_month:\n",
    "            return list(range(start_month, end_month + 1))\n",
    "        else:\n",
    "            return list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    def filter_data_for_months(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Filter dataframe for month range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return df[df['month'].isin(months_in_range)].copy()\n",
    "    \n",
    "    def create_month_order_map(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create a mapping for sorting months in the specified order\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return {month: idx for idx, month in enumerate(months_in_range)}\n",
    "    \n",
    "    def get_forecast_year(self, month):\n",
    "        \"\"\"\n",
    "        Determine the forecast year for a given month based on current date\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_year = current_date.year\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        # If the forecast month is >= current month, it's this year\n",
    "        # Otherwise it's next year (handling year wrap)\n",
    "        if month >= current_month:\n",
    "            return current_year\n",
    "        else:\n",
    "            return current_year + 1\n",
    "    \n",
    "    def compress_outliers(self, values, lower_pct=10, upper_pct=90):\n",
    "        \"\"\"\n",
    "        Compress outliers using logarithmic compression\n",
    "        This keeps outliers in the distribution but makes them manageable for visualization\n",
    "        \"\"\"\n",
    "        # Calculate compression thresholds\n",
    "        P_lower = np.percentile(values, lower_pct)\n",
    "        P_upper = np.percentile(values, upper_pct)\n",
    "        \n",
    "        # Create compressed values array\n",
    "        compressed = np.copy(values)\n",
    "        \n",
    "        # Compress lower tail (negative extremes)\n",
    "        lower_mask = values < P_lower\n",
    "        if np.any(lower_mask):\n",
    "            # Use logarithmic compression for negative tail\n",
    "            # Shift to make positive for log, then shift back\n",
    "            offset = P_lower - values[lower_mask]\n",
    "            compressed[lower_mask] = P_lower - np.log1p(offset)\n",
    "        \n",
    "        # Compress upper tail (positive extremes)\n",
    "        upper_mask = values > P_upper\n",
    "        if np.any(upper_mask):\n",
    "            # Use logarithmic compression for positive tail\n",
    "            offset = values[upper_mask] - P_upper\n",
    "            compressed[upper_mask] = P_upper + np.log1p(offset)\n",
    "        \n",
    "        # Return compressed values and compression info\n",
    "        compression_info = {\n",
    "            'P_lower': P_lower,\n",
    "            'P_upper': P_upper,\n",
    "            'n_compressed_lower': np.sum(lower_mask),\n",
    "            'n_compressed_upper': np.sum(upper_mask),\n",
    "            'original_min': np.min(values),\n",
    "            'original_max': np.max(values),\n",
    "            'compressed_min': np.min(compressed),\n",
    "            'compressed_max': np.max(compressed)\n",
    "        }\n",
    "        \n",
    "        return compressed, compression_info\n",
    "    \n",
    "    def calculate_extreme_statistics(self, prices, generation=None):\n",
    "        \"\"\"\n",
    "        Enhanced extreme statistics calculation\n",
    "        \"\"\"\n",
    "        extreme_stats = {}\n",
    "        \n",
    "        # Overall distribution info\n",
    "        extreme_stats['min'] = np.min(prices)\n",
    "        extreme_stats['max'] = np.max(prices)\n",
    "        extreme_stats['mean'] = np.mean(prices)\n",
    "        extreme_stats['std'] = np.std(prices)\n",
    "        \n",
    "        # Negative price analysis\n",
    "        negative_mask = prices < self.negative_threshold\n",
    "        extreme_stats['negative_count'] = negative_mask.sum()\n",
    "        extreme_stats['negative_pct'] = negative_mask.sum() / len(prices) * 100\n",
    "        \n",
    "        if negative_mask.sum() > 0:\n",
    "            neg_prices = prices[negative_mask]\n",
    "            extreme_stats['negative_mean'] = np.mean(neg_prices)\n",
    "            extreme_stats['negative_worst'] = np.min(neg_prices)\n",
    "            if generation is not None:\n",
    "                extreme_stats['negative_avg_gen'] = np.mean(generation[negative_mask])\n",
    "        \n",
    "        # Spike analysis\n",
    "        spike_mask = prices > self.spike_threshold\n",
    "        extreme_stats['spike_count'] = spike_mask.sum()\n",
    "        extreme_stats['spike_pct'] = spike_mask.sum() / len(prices) * 100\n",
    "        \n",
    "        if spike_mask.sum() > 0:\n",
    "            spike_prices = prices[spike_mask]\n",
    "            extreme_stats['spike_mean'] = np.mean(spike_prices)\n",
    "            extreme_stats['spike_worst'] = np.max(spike_prices)\n",
    "            if generation is not None:\n",
    "                extreme_stats['spike_avg_gen'] = np.mean(generation[spike_mask])\n",
    "        \n",
    "        # Extreme spike count\n",
    "        extreme_spike_mask = prices > self.extreme_spike_threshold\n",
    "        extreme_stats['extreme_spike_count'] = extreme_spike_mask.sum()\n",
    "        \n",
    "        return extreme_stats\n",
    "    \n",
    "    def calculate_hourly_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate hourly price statistics with percentile compression\n",
    "        \"\"\"\n",
    "        print(\"\\nâš¡ Calculating HOURLY price statistics...\")\n",
    "        \n",
    "        grouped = df_filtered.groupby(['month', 'day', 'hour'])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (month, day, hour), group in grouped:\n",
    "            if len(group) < 5:  # Skip if too few data points\n",
    "                continue\n",
    "            \n",
    "            prices = group['price'].values\n",
    "            generation = group['generation_mw'].values\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month)\n",
    "            \n",
    "            # Apply percentile compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                prices, \n",
    "                self.compression_lower, \n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            # Create datetime label\n",
    "            datetime_label = f\"{self.month_names[month]}-{day:02d} {hour:02d}:00\"\n",
    "            \n",
    "            # Main statistics on COMPRESSED data for visualization\n",
    "            stats = {\n",
    "                'datetime_label': datetime_label,\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'hour': hour,\n",
    "                'month_order': month_order_map[month],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(group),\n",
    "                'avg_generation': np.mean(generation)\n",
    "            }\n",
    "            \n",
    "            # Calculate percentiles on COMPRESSED data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Also store ACTUAL percentiles for reference\n",
    "            stats['actual_mean'] = np.mean(prices)\n",
    "            stats['actual_min'] = np.min(prices)\n",
    "            stats['actual_max'] = np.max(prices)\n",
    "            stats['actual_p5'] = np.percentile(prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames and sort\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} hourly slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_daily_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate daily GENERATION-WEIGHTED price statistics with compression\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“… Calculating DAILY generation-weighted price statistics...\")\n",
    "        \n",
    "        # First calculate generation-weighted prices for each day\n",
    "        def calc_weighted_daily(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return pd.Series({\n",
    "                    'weighted_price': np.nan,\n",
    "                    'total_generation': 0,\n",
    "                    'generating_hours': 0\n",
    "                })\n",
    "            \n",
    "            gen_positive = group.loc[mask]\n",
    "            weighted_price = (gen_positive['price'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "            \n",
    "            return pd.Series({\n",
    "                'weighted_price': weighted_price,\n",
    "                'total_generation': group['generation_mw'].sum(),\n",
    "                'generating_hours': mask.sum()\n",
    "            })\n",
    "        \n",
    "        # Calculate daily aggregates for each year\n",
    "        daily_data = df_filtered.groupby(['year', 'month', 'day']).apply(calc_weighted_daily).reset_index()\n",
    "        \n",
    "        # Now calculate statistics across years for each day\n",
    "        grouped = daily_data.groupby(['month', 'day'])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (month, day), group in grouped:\n",
    "            valid_group = group[group['weighted_price'].notna()]\n",
    "            if len(valid_group) < 5:\n",
    "                continue\n",
    "            \n",
    "            weighted_prices = valid_group['weighted_price'].values\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month)\n",
    "            \n",
    "            # Apply compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                weighted_prices,\n",
    "                self.compression_lower,\n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            # Create date label\n",
    "            date_label = f\"{self.month_names[month]}-{day:02d}\"\n",
    "            \n",
    "            # Main statistics on compressed data\n",
    "            stats = {\n",
    "                'date_label': date_label,\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'month_order': month_order_map[month],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(valid_group),\n",
    "                'avg_generation_mwh': valid_group['total_generation'].mean(),\n",
    "                'avg_generating_hours': valid_group['generating_hours'].mean()\n",
    "            }\n",
    "            \n",
    "            # Percentiles on compressed data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Actual percentiles for reference\n",
    "            stats['actual_mean'] = np.mean(weighted_prices)\n",
    "            stats['actual_min'] = np.min(weighted_prices)\n",
    "            stats['actual_max'] = np.max(weighted_prices)\n",
    "            stats['actual_p5'] = np.percentile(weighted_prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(weighted_prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(weighted_prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(weighted_prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} daily slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_monthly_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate monthly GENERATION-WEIGHTED price statistics with compression\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š Calculating MONTHLY generation-weighted price statistics...\")\n",
    "        \n",
    "        # Calculate monthly weighted prices\n",
    "        def calc_weighted_monthly(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return pd.Series({\n",
    "                    'weighted_price': np.nan,\n",
    "                    'total_generation': 0,\n",
    "                    'generating_hours': 0\n",
    "                })\n",
    "            \n",
    "            gen_positive = group.loc[mask]\n",
    "            weighted_price = (gen_positive['price'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "            \n",
    "            return pd.Series({\n",
    "                'weighted_price': weighted_price,\n",
    "                'total_generation': group['generation_mw'].sum(),\n",
    "                'generating_hours': mask.sum()\n",
    "            })\n",
    "        \n",
    "        # Calculate monthly aggregates for each year\n",
    "        monthly_data = df_filtered.groupby(['year', 'month']).apply(calc_weighted_monthly).reset_index()\n",
    "        \n",
    "        # Calculate statistics across years for each month\n",
    "        grouped = monthly_data.groupby('month')\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for month, group in grouped:\n",
    "            valid_group = group[group['weighted_price'].notna()]\n",
    "            if len(valid_group) < 5:\n",
    "                continue\n",
    "            \n",
    "            weighted_prices = valid_group['weighted_price'].values\n",
    "            \n",
    "            month_idx = int(month)\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month_idx)\n",
    "            \n",
    "            # Apply compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                weighted_prices,\n",
    "                self.compression_lower,\n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            stats = {\n",
    "                'month_name': self.month_names_full[month_idx],\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month_idx,\n",
    "                'month_order': month_order_map[month_idx],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(valid_group),\n",
    "                'avg_generation_mwh': valid_group['total_generation'].mean(),\n",
    "                'avg_generating_hours': valid_group['generating_hours'].mean()\n",
    "            }\n",
    "            \n",
    "            # Percentiles on compressed data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Actual values\n",
    "            stats['actual_mean'] = np.mean(weighted_prices)\n",
    "            stats['actual_min'] = np.min(weighted_prices)\n",
    "            stats['actual_max'] = np.max(weighted_prices)\n",
    "            stats['actual_p5'] = np.percentile(weighted_prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(weighted_prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(weighted_prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(weighted_prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} months\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def create_hourly_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly price timeseries with years as columns\n",
    "        \"\"\"\n",
    "        print(\"\\nâ° Creating HOURLY price timeseries...\")\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        df_work = df_filtered.copy()\n",
    "        \n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Pivot for prices\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values='price',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} hourly slots\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_hourly_timeseries_compressed(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly price timeseries with COMPRESSED values\n",
    "        MODIFIED: Uses P25-P75 compression instead of P10-P90\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ—œï¸  Creating COMPRESSED hourly price timeseries...\")\n",
    "        \n",
    "        # LOCAL VARIABLES - won't affect class-level compression settings\n",
    "        local_compression_lower = 25  # P25 instead of P10\n",
    "        local_compression_upper = 75  # P75 instead of P90\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        df_work = df_filtered.copy()\n",
    "        \n",
    "        # First, calculate P25 and P75 for each hour slot across all years\n",
    "        compression_params = {}\n",
    "        grouped = df_work.groupby(['month', 'day', 'hour'])\n",
    "        \n",
    "        for (month, day, hour), group in grouped:\n",
    "            if len(group) >= 5:  # Need enough data points\n",
    "                prices = group['price'].values\n",
    "                # Use LOCAL variables here, not class variables\n",
    "                P_lower = np.percentile(prices, local_compression_lower)  # P25\n",
    "                P_upper = np.percentile(prices, local_compression_upper)  # P75\n",
    "                compression_params[(month, day, hour)] = (P_lower, P_upper)\n",
    "        \n",
    "        # Now apply compression to each individual value\n",
    "        def compress_value(row):\n",
    "            key = (row['month'], row['day'], row['hour'])\n",
    "            if key in compression_params:\n",
    "                P_lower, P_upper = compression_params[key]\n",
    "                value = row['price']\n",
    "                \n",
    "                if value < P_lower:\n",
    "                    offset = P_lower - value\n",
    "                    return P_lower - np.log1p(offset)\n",
    "                elif value > P_upper:\n",
    "                    offset = value - P_upper\n",
    "                    return P_upper + np.log1p(offset)\n",
    "                else:\n",
    "                    return value\n",
    "            else:\n",
    "                return row['price']  # No compression if insufficient data\n",
    "        \n",
    "        df_work['compressed_price'] = df_work.apply(compress_value, axis=1)\n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Pivot for compressed prices\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values='compressed_price',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created compressed timeseries for {len(pivot_df)} hourly slots\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        print(f\"   ğŸ“Œ Using P25-P75 compression (more aggressive than statistics files)\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_daily_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create daily GENERATION-WEIGHTED price timeseries\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“… Creating DAILY generation-weighted price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted daily prices\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            return (gen_positive['price'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_daily = df_filtered.groupby(['year', 'month', 'day']).apply(calc_weighted_price).reset_index()\n",
    "        df_daily.columns = ['year', 'month', 'day', 'weighted_price']\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        \n",
    "        df_daily['month_order'] = df_daily['month'].map(month_order_map)\n",
    "        \n",
    "        pivot_df = df_daily.pivot_table(\n",
    "            index=['month', 'day', 'month_order'],\n",
    "            columns='year',\n",
    "            values='weighted_price',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['date_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d}\",\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['date_label', 'month', 'day'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} daily slots\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_monthly_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create monthly GENERATION-WEIGHTED price timeseries\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š Creating MONTHLY generation-weighted price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted monthly prices\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            return (gen_positive['price'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_monthly = df_filtered.groupby(['year', 'month']).apply(calc_weighted_price).reset_index()\n",
    "        df_monthly.columns = ['year', 'month', 'weighted_price']\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        \n",
    "        df_monthly['month_order'] = df_monthly['month'].map(month_order_map)\n",
    "        \n",
    "        pivot_df = df_monthly.pivot_table(\n",
    "            index=['month', 'month_order'],\n",
    "            columns='year',\n",
    "            values='weighted_price',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['month_name'] = pivot_df['month'].apply(lambda x: self.month_names_full[int(x)])\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['month_name', 'month'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} months\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def save_all_results(self, hourly_stats, daily_stats, monthly_stats, \n",
    "                        hourly_ts, hourly_ts_compressed, daily_ts, monthly_ts, site_name):\n",
    "        \"\"\"\n",
    "        Save all files in the new structure: Renewable Portfolio LLC/{site_name}/Price/\n",
    "        \"\"\"\n",
    "        # Create the site-specific Price folder\n",
    "        price_path = self.base_output_path / site_name / 'Price'\n",
    "        price_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create plots folder for the site (if not already created by generation script)\n",
    "        plots_path = self.base_output_path / site_name / 'plots'\n",
    "        plots_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save hourly statistics (CHANGED: stats -> forecast)\n",
    "        hourly_file = f\"{site_name}_price_hourly_forecast.csv\"\n",
    "        hourly_path = price_path / hourly_file\n",
    "        \n",
    "        cols_hourly = ['datetime_label', 'year', 'month', 'day', 'hour', 'mean', 'std_dev'] + \\\n",
    "                     [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                     ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10', \n",
    "                      'actual_p90', 'actual_p95', 'count', 'avg_generation']\n",
    "        \n",
    "        hourly_stats[cols_hourly].to_csv(hourly_path, index=False, float_format='%.3f')\n",
    "        print(f\"\\nğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{hourly_file}\")\n",
    "        \n",
    "        # Save daily statistics (CHANGED: stats -> forecast)\n",
    "        daily_file = f\"{site_name}_price_daily_forecast.csv\"\n",
    "        daily_path = price_path / daily_file\n",
    "        \n",
    "        cols_daily = ['date_label', 'year', 'month', 'day', 'mean', 'std_dev'] + \\\n",
    "                    [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                    ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10',\n",
    "                     'actual_p90', 'actual_p95', 'count', 'avg_generation_mwh', 'avg_generating_hours']\n",
    "        \n",
    "        daily_stats[cols_daily].to_csv(daily_path, index=False, float_format='%.3f')\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{daily_file}\")\n",
    "        \n",
    "        # Save monthly statistics (CHANGED: stats -> forecast)\n",
    "        monthly_file = f\"{site_name}_price_monthly_forecast.csv\"\n",
    "        monthly_path = price_path / monthly_file\n",
    "        \n",
    "        cols_monthly = ['month_name', 'year', 'month', 'mean', 'std_dev'] + \\\n",
    "                      [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                      ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10',\n",
    "                       'actual_p90', 'actual_p95', 'count', 'avg_generation_mwh', 'avg_generating_hours']\n",
    "        \n",
    "        monthly_stats[cols_monthly].to_csv(monthly_path, index=False, float_format='%.3f')\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{monthly_file}\")\n",
    "        \n",
    "        # Save hourly timeseries (original values)\n",
    "        hourly_ts_file = f\"{site_name}_price_hourly_timeseries.csv\"\n",
    "        hourly_ts_path = price_path / hourly_ts_file\n",
    "        hourly_ts_save = hourly_ts.copy()\n",
    "        year_cols = [col for col in hourly_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            hourly_ts_save[col] = hourly_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        hourly_ts_save.to_csv(hourly_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{hourly_ts_file}\")\n",
    "        \n",
    "        # Save hourly COMPRESSED timeseries\n",
    "        hourly_compressed_file = f\"{site_name}_price_hourly_timeseries_compressed.csv\"\n",
    "        hourly_compressed_path = price_path / hourly_compressed_file\n",
    "        hourly_ts_compressed_save = hourly_ts_compressed.copy()\n",
    "        year_cols = [col for col in hourly_ts_compressed_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            hourly_ts_compressed_save[col] = hourly_ts_compressed_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        hourly_ts_compressed_save.to_csv(hourly_compressed_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{hourly_compressed_file}\")\n",
    "        \n",
    "        # Save daily timeseries (weighted)\n",
    "        daily_ts_file = f\"{site_name}_price_daily_timeseries.csv\"\n",
    "        daily_ts_path = price_path / daily_ts_file\n",
    "        daily_ts_save = daily_ts.copy()\n",
    "        year_cols = [col for col in daily_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            daily_ts_save[col] = daily_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        daily_ts_save.to_csv(daily_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{daily_ts_file}\")\n",
    "        \n",
    "        # Save monthly timeseries (weighted)\n",
    "        monthly_ts_file = f\"{site_name}_price_monthly_timeseries.csv\"\n",
    "        monthly_ts_path = price_path / monthly_ts_file\n",
    "        monthly_ts_save = monthly_ts.copy()\n",
    "        year_cols = [col for col in monthly_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            monthly_ts_save[col] = monthly_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        monthly_ts_save.to_csv(monthly_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price/{monthly_ts_file}\")\n",
    "    \n",
    "    def print_sample_results(self, hourly_stats, daily_stats):\n",
    "        \"\"\"\n",
    "        Print formatted sample results showing compression effect\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE RESULTS WITH COMPRESSION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Sample hourly statistics\n",
    "        print(\"\\nâš¡ HOURLY PRICE STATISTICS SAMPLE:\")\n",
    "        if not hourly_stats.empty:\n",
    "            mid_month = hourly_stats['month'].min()\n",
    "            sample = hourly_stats[(hourly_stats['month'] == mid_month) & \n",
    "                                (hourly_stats['day'] == 15) & \n",
    "                                (hourly_stats['hour'] == 12)]\n",
    "            \n",
    "            if not sample.empty:\n",
    "                row = sample.iloc[0]\n",
    "                \n",
    "                print(f\"\\n   {row['datetime_label']} (Year: {row['year']}):\")\n",
    "                print(f\"   Original range: ${row['actual_min']:.2f} to ${row['actual_max']:.2f}\")\n",
    "                print(f\"   Mean: ${row['mean']:.2f}, P10-P90: ${row['p10']:.2f}-${row['p90']:.2f}\")\n",
    "                print(f\"   (Statistics based on compressed values)\")\n",
    "        \n",
    "        # Sample daily statistics\n",
    "        print(\"\\nğŸ“… DAILY WEIGHTED PRICE STATISTICS SAMPLE:\")\n",
    "        if not daily_stats.empty:\n",
    "            mid_month = daily_stats['month'].min()\n",
    "            sample = daily_stats[(daily_stats['month'] == mid_month) & (daily_stats['day'] == 15)]\n",
    "            \n",
    "            if not sample.empty:\n",
    "                row = sample.iloc[0]\n",
    "                print(f\"\\n   {row['date_label']} (Year: {row['year']}):\")\n",
    "                print(f\"   Weighted avg: ${row['mean']:.2f}, P10-P90: ${row['p10']:.2f}-${row['p90']:.2f}\")\n",
    "                print(f\"   Based on {row['avg_generating_hours']:.1f} generating hours/day\")\n",
    "    \n",
    "    def process_single_site(self, site_name, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Process a single site with given month range\n",
    "        \"\"\"\n",
    "        # Create month order mapping\n",
    "        month_order_map = self.create_month_order_map(start_month, end_month)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {site_name}\")\n",
    "        \n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        num_months = len(months_in_range)\n",
    "        \n",
    "        if start_month <= end_month:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} ({num_months} months)\")\n",
    "        else:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} (year-wrapping, {num_months} months)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Use the mapping to get the actual filename\n",
    "        actual_filename = self.site_file_map.get(site_name)\n",
    "        if actual_filename:\n",
    "            file_path = self.data_path / actual_filename\n",
    "        else:\n",
    "            # Fallback - try the standard naming convention\n",
    "            file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "            \n",
    "        print(f\"\\nğŸ“ Loading data from: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            \n",
    "            # Extract day of month from datetime since it's not in the columns\n",
    "            df['day'] = df['datetime'].dt.day\n",
    "            \n",
    "            # Ensure all columns are integers\n",
    "            df['year'] = df['year'].astype(int)\n",
    "            df['month'] = df['month'].astype(int)\n",
    "            df['hour'] = df['hour'].astype(int)\n",
    "            \n",
    "            # Filter for selected months\n",
    "            df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "            \n",
    "            # Get data summary\n",
    "            years_available = sorted(df_filtered['year'].unique())\n",
    "            print(f\"\\nğŸ“Š Data summary:\")\n",
    "            print(f\"   Years available: {years_available[0]} to {years_available[-1]} ({len(years_available)} years)\")\n",
    "            print(f\"   Total data points: {len(df_filtered):,}\")\n",
    "            print(f\"   Price range: ${df_filtered['price'].min():.2f} to ${df_filtered['price'].max():.2f}\")\n",
    "            print(f\"   Negative price hours: {(df_filtered['price'] < 0).sum()} ({(df_filtered['price'] < 0).sum()/len(df_filtered)*100:.1f}%)\")\n",
    "            \n",
    "            # Updated note about year-wrapping\n",
    "            if start_month > end_month:\n",
    "                print(f\"\\n   â„¹ï¸  Note: Year-wrapping range detected!\")\n",
    "                print(f\"   First year ({years_available[0]}) and last year ({years_available[-1]}) may have partial data\")\n",
    "                print(f\"   All available data will be included in the timeseries files\")\n",
    "            \n",
    "            # Calculate statistics at all three levels\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"PRICE DISTRIBUTION STATISTICS\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            hourly_stats = self.calculate_hourly_statistics(df_filtered, month_order_map)\n",
    "            daily_stats = self.calculate_daily_statistics(df_filtered, month_order_map)\n",
    "            monthly_stats = self.calculate_monthly_statistics(df_filtered, month_order_map)\n",
    "            \n",
    "            # Create timeseries\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"PRICE TIMESERIES GENERATION\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            hourly_ts = self.create_hourly_timeseries(df_filtered, month_order_map)\n",
    "            hourly_ts_compressed = self.create_hourly_timeseries_compressed(df_filtered, month_order_map)\n",
    "            daily_ts = self.create_daily_timeseries(df_filtered, month_order_map)\n",
    "            monthly_ts = self.create_monthly_timeseries(df_filtered, month_order_map)\n",
    "            \n",
    "            # Print samples\n",
    "            self.print_sample_results(hourly_stats, daily_stats)\n",
    "            \n",
    "            # Save all results\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"SAVING RESULTS\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            self.save_all_results(hourly_stats, daily_stats, monthly_stats,\n",
    "                                hourly_ts, hourly_ts_compressed, daily_ts, monthly_ts, site_name)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error processing {site_name}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def run_simulation(self):\n",
    "        \"\"\"\n",
    "        Main function to run the price simulation\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ’° Price Simulation with Outlier Compression\")\n",
    "        print(\"   (Handles extreme prices elegantly)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            return\n",
    "        \n",
    "        # Get automatic month range\n",
    "        start_month, end_month = self.get_automatic_month_range()\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"ğŸš€ PROCESSING ALL SITES\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(self.available_sites, 1):\n",
    "                print(f\"\\n[{i}/{len(self.available_sites)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name, start_month, end_month):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"âœ¨ ALL SITES PROCESSING COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\nğŸ“Š Summary:\")\n",
    "            print(f\"   âœ… Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   âŒ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "            print(f\"\\nğŸ“ Files saved in: Renewable Portfolio LLC/[site_name]/Price/\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection, start_month, end_month):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"âœ¨ PRICE SIMULATION COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\nAnalysis created for {site_selection}\")\n",
    "                \n",
    "                print(f\"12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "                \n",
    "                print(f\"\\nğŸ“ Files saved in:\")\n",
    "                print(f\"   Renewable Portfolio LLC/{site_selection}/Price/\")\n",
    "                print(\"     â€¢ Hourly/Daily/Monthly price statistics (with year column)\")\n",
    "                print(\"     â€¢ Hourly/Daily/Monthly price timeseries\")\n",
    "                print(\"     â€¢ Hourly compressed timeseries for visualization\")\n",
    "                print(f\"   Renewable Portfolio LLC/{site_selection}/plots/\")\n",
    "                print(\"     â€¢ (Ready for future visualizations)\")\n",
    "                \n",
    "                print(\"\\nğŸ’¡ Key features:\")\n",
    "                print(\"   â€¢ Outliers compressed logarithmically (P10-P90)\")\n",
    "                print(\"   â€¢ Full P1-P99 percentiles available\")\n",
    "                print(\"   â€¢ Actual values tracked for reference\")\n",
    "                print(\"   â€¢ Daily and Monthly use generation-weighted prices\")\n",
    "        \n",
    "        # Ask if user wants to create another simulation\n",
    "        another = input(\"\\nğŸ”„ Create another price simulation? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_simulation()\n",
    "\n",
    "# Run the simulation\n",
    "if __name__ == \"__main__\":\n",
    "    simulator = PriceSimulation()\n",
    "    simulator.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0f169",
   "metadata": {},
   "source": [
    "# Price_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635d8a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Initializing Day-Ahead Price Simulation...\n",
      "   Found 7 combined files\n",
      "\n",
      "ğŸ’° Day-Ahead Price Simulation with Outlier Compression\n",
      "   (Handles extreme day-ahead prices elegantly)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DAY-AHEAD PRICE SIMULATION WITH OUTLIER COMPRESSION\n",
      "============================================================\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Process all sites at once)\n",
      "1. Blue_Wing_Solar_Energy_Generator\n",
      "2. High_Lonesome_Wind_Power\n",
      "3. Midway_Solar_Farm_III\n",
      "4. Misae_Solar\n",
      "5. Mount_Signal_Solar_Farm_II\n",
      "6. RE_Mustang_LLC\n",
      "7. Stanton_Wind_Energy_LLC\n",
      "============================================================\n",
      "\n",
      "ğŸ“… Auto-detected period: Jul to Jun (12 months)\n",
      "   Starting from current month: Jul\n",
      "\n",
      "============================================================\n",
      "ğŸš€ PROCESSING ALL SITES\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "============================================================\n",
      "Processing: Blue_Wing_Solar_Energy_Generator\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Blue_Wing_Solar_Energy_Generator_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,115\n",
      "   Day-ahead price range: $-27.74 to $999.04\n",
      "   Negative day-ahead price hours: 80 (0.1%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $5.12 to $112.53\n",
      "   Mean: $23.33, P10-P90: $18.38-$28.92\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $23.83, P10-P90: $19.06-$30.44\n",
      "   Based on 10.4 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_da/Blue_Wing_Solar_Energy_Generator_price_da_monthly_timeseries.csv\n",
      "\n",
      "[2/7] Processing High_Lonesome_Wind_Power...\n",
      "\n",
      "============================================================\n",
      "Processing: High_Lonesome_Wind_Power\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: High_Lonesome_Wind_Power_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2010 to 2025 (16 years)\n",
      "   Total data points: 126,010\n",
      "   Day-ahead price range: $-57.01 to $998.25\n",
      "   Negative day-ahead price hours: 2647 (2.1%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2010) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $1.21 to $134.84\n",
      "   Mean: $20.45, P10-P90: $5.69-$28.45\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $24.39, P10-P90: $8.91-$35.84\n",
      "   Based on 19.6 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/High_Lonesome_Wind_Power/Price_da/High_Lonesome_Wind_Power_price_da_monthly_timeseries.csv\n",
      "\n",
      "[3/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "============================================================\n",
      "Processing: Midway_Solar_Farm_III\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Midway_Solar_Farm_III_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,401\n",
      "   Day-ahead price range: $-998.31 to $997.97\n",
      "   Negative day-ahead price hours: 5587 (4.8%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-30.38 to $124.19\n",
      "   Mean: $30.44, P10-P90: $-10.88-$80.12\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $35.31, P10-P90: $-2.83-$85.05\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_da/Midway_Solar_Farm_III_price_da_monthly_timeseries.csv\n",
      "\n",
      "[4/7] Processing Misae_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing: Misae_Solar\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Misae_Solar_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,097\n",
      "   Day-ahead price range: $-37.76 to $996.28\n",
      "   Negative day-ahead price hours: 7680 (6.7%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-12.23 to $138.69\n",
      "   Mean: $18.88, P10-P90: $0.60-$27.45\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $20.71, P10-P90: $5.38-$29.12\n",
      "   Based on 10.2 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Misae_Solar/Price_da/Misae_Solar_price_da_monthly_timeseries.csv\n",
      "\n",
      "[5/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "============================================================\n",
      "Processing: Mount_Signal_Solar_Farm_II\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Mount_Signal_Solar_Farm_II_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,401\n",
      "   Day-ahead price range: $-904.62 to $997.97\n",
      "   Negative day-ahead price hours: 4039 (3.5%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $5.09 to $90.83\n",
      "   Mean: $29.05, P10-P90: $6.18-$68.24\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $33.07, P10-P90: $13.21-$73.29\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_da/Mount_Signal_Solar_Farm_II_price_da_monthly_timeseries.csv\n",
      "\n",
      "[6/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing: RE_Mustang_LLC\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: RE_Mustang_LLC_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2012 to 2025 (14 years)\n",
      "   Total data points: 115,385\n",
      "   Day-ahead price range: $-56.86 to $981.00\n",
      "   Negative day-ahead price hours: 3501 (3.0%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2012) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 14 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $-7.29 to $167.85\n",
      "   Mean: $36.77, P10-P90: $11.91-$81.59\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $40.47, P10-P90: $18.06-$86.88\n",
      "   Based on 10.0 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/RE_Mustang_LLC/Price_da/RE_Mustang_LLC_price_da_monthly_timeseries.csv\n",
      "\n",
      "[7/7] Processing Stanton_Wind_Energy_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing: Stanton_Wind_Energy_LLC\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Loading data from: Stanton_Wind_Energy_LLC_generation_price_combined.csv\n",
      "\n",
      "ğŸ“Š Data summary:\n",
      "   Years available: 2010 to 2025 (16 years)\n",
      "   Total data points: 126,008\n",
      "   Day-ahead price range: $-34.62 to $999.53\n",
      "   Negative day-ahead price hours: 1969 (1.6%)\n",
      "\n",
      "   â„¹ï¸  Note: Year-wrapping range detected!\n",
      "   First year (2010) and last year (2025) may have partial data\n",
      "   All available data will be included in the timeseries files\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE DISTRIBUTION STATISTICS\n",
      "----------------------------------------\n",
      "\n",
      "âš¡ Calculating HOURLY day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 8760 hourly slots\n",
      "\n",
      "ğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 365 daily slots\n",
      "\n",
      "ğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\n",
      "   âœ“ Calculated statistics for 12 months\n",
      "\n",
      "----------------------------------------\n",
      "DAY-AHEAD PRICE TIMESERIES GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "â° Creating HOURLY day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 8784 hourly slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 366 daily slots\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "ğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\n",
      "   âœ“ Created timeseries for 12 months\n",
      "   âœ“ Including data from all 16 years\n",
      "\n",
      "============================================================\n",
      "SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\n",
      "============================================================\n",
      "\n",
      "âš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 12:00 (Year: 2026):\n",
      "   Original range: $0.08 to $136.04\n",
      "   Mean: $21.02, P10-P90: $4.50-$31.71\n",
      "   (Statistics based on compressed values)\n",
      "\n",
      "ğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\n",
      "\n",
      "   Jan-15 (Year: 2026):\n",
      "   Weighted avg: $30.62, P10-P90: $14.99-$58.40\n",
      "   Based on 19.5 generating hours/day\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_hourly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_daily_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_monthly_forecast.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_hourly_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_daily_timeseries.csv\n",
      "ğŸ’¾ Saved: Renewable Portfolio LLC/Stanton_Wind_Energy_LLC/Price_da/Stanton_Wind_Energy_LLC_price_da_monthly_timeseries.csv\n",
      "\n",
      "============================================================\n",
      "âœ¨ ALL SITES PROCESSING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   âœ… Successfully processed: 7 sites\n",
      "\n",
      "12-month period: Jul to Jun\n",
      "\n",
      "ğŸ“ Files saved in: Renewable Portfolio LLC/[site_name]/Price_da/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PriceDayAheadSimulation:\n",
    "    \"\"\"\n",
    "    Create statistical DAY-AHEAD price profiles with percentile compression for outliers\n",
    "    Handles extreme prices elegantly while preserving their presence in distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"\\nğŸ”§ Initializing Day-Ahead Price Simulation...\")\n",
    "        \n",
    "        # Define paths - reading from resurety_data folder (UPDATED PATH)\n",
    "        self.data_path = Path('resurety_data')  # Changed from '../resurety_data'\n",
    "        self.base_output_path = Path('Renewable Portfolio LLC')  # New base output path\n",
    "        \n",
    "        # Get available combined files and create mapping\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = []\n",
    "        self.site_file_map = {}  # Map clean site names to actual filenames\n",
    "        \n",
    "        for f in self.available_files:\n",
    "            # Store the full filename (without path)\n",
    "            full_filename = f.name\n",
    "            \n",
    "            # Extract site name by removing '_generation_price_combined.csv'\n",
    "            site_name = f.stem.replace('_generation_price_combined', '')\n",
    "            \n",
    "            # Clean up the site name by removing '_hourly' to avoid redundancy in output files\n",
    "            clean_site_name = site_name.replace('_hourly', '')\n",
    "            \n",
    "            self.available_sites.append(clean_site_name)\n",
    "            # Map the clean name to the actual filename\n",
    "            self.site_file_map[clean_site_name] = full_filename\n",
    "        \n",
    "        print(f\"   Found {len(self.available_files)} combined files\")\n",
    "        \n",
    "        # Define percentiles for FULL distribution (including compressed outliers)\n",
    "        self.full_percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        \n",
    "        # Define compression thresholds (P10 and P90 for compression)\n",
    "        self.compression_lower = 10\n",
    "        self.compression_upper = 90\n",
    "        \n",
    "        # Define thresholds for extreme event tracking\n",
    "        self.negative_threshold = 0\n",
    "        self.spike_threshold = 100\n",
    "        self.extreme_spike_threshold = 200\n",
    "        \n",
    "        # Month names for labeling\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with option for all sites\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DAY-AHEAD PRICE SIMULATION WITH OUTLIER COMPRESSION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"âŒ No combined generation-price files found in resurety_data!\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(\"0. ALL SITES (Process all sites at once)\")\n",
    "        for i, site in enumerate(self.available_sites):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\nğŸ’° Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES'\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(self.available_sites):\n",
    "                        return self.available_sites[idx]\n",
    "                    else:\n",
    "                        print(\"âŒ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"âŒ Please enter a valid number!\")\n",
    "    \n",
    "    def get_automatic_month_range(self):\n",
    "        \"\"\"\n",
    "        Automatically determine month range: current month to 11 months later\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        # Use current month as start\n",
    "        start_month = current_month\n",
    "        \n",
    "        # End month is one month before start month (12 month cycle)\n",
    "        if start_month == 1:\n",
    "            end_month = 12\n",
    "        else:\n",
    "            end_month = start_month - 1\n",
    "        \n",
    "        print(f\"\\nğŸ“… Auto-detected period: {self.month_names[start_month]} to {self.month_names[end_month]} (12 months)\")\n",
    "        print(f\"   Starting from current month: {self.month_names[current_month]}\")\n",
    "        \n",
    "        return start_month, end_month\n",
    "    \n",
    "    def get_months_in_range(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Get list of months in range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        if start_month <= end_month:\n",
    "            return list(range(start_month, end_month + 1))\n",
    "        else:\n",
    "            return list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    def filter_data_for_months(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Filter dataframe for month range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return df[df['month'].isin(months_in_range)].copy()\n",
    "    \n",
    "    def create_month_order_map(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create a mapping for sorting months in the specified order\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return {month: idx for idx, month in enumerate(months_in_range)}\n",
    "    \n",
    "    def get_forecast_year(self, month):\n",
    "        \"\"\"\n",
    "        Determine the forecast year for a given month based on current date\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_year = current_date.year\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        # If the forecast month is >= current month, it's this year\n",
    "        # Otherwise it's next year (handling year wrap)\n",
    "        if month >= current_month:\n",
    "            return current_year\n",
    "        else:\n",
    "            return current_year + 1\n",
    "    \n",
    "    def compress_outliers(self, values, lower_pct=10, upper_pct=90):\n",
    "        \"\"\"\n",
    "        Compress outliers using logarithmic compression\n",
    "        This keeps outliers in the distribution but makes them manageable for visualization\n",
    "        \"\"\"\n",
    "        # Calculate compression thresholds\n",
    "        P_lower = np.percentile(values, lower_pct)\n",
    "        P_upper = np.percentile(values, upper_pct)\n",
    "        \n",
    "        # Create compressed values array\n",
    "        compressed = np.copy(values)\n",
    "        \n",
    "        # Compress lower tail (negative extremes)\n",
    "        lower_mask = values < P_lower\n",
    "        if np.any(lower_mask):\n",
    "            # Use logarithmic compression for negative tail\n",
    "            # Shift to make positive for log, then shift back\n",
    "            offset = P_lower - values[lower_mask]\n",
    "            compressed[lower_mask] = P_lower - np.log1p(offset)\n",
    "        \n",
    "        # Compress upper tail (positive extremes)\n",
    "        upper_mask = values > P_upper\n",
    "        if np.any(upper_mask):\n",
    "            # Use logarithmic compression for positive tail\n",
    "            offset = values[upper_mask] - P_upper\n",
    "            compressed[upper_mask] = P_upper + np.log1p(offset)\n",
    "        \n",
    "        # Return compressed values and compression info\n",
    "        compression_info = {\n",
    "            'P_lower': P_lower,\n",
    "            'P_upper': P_upper,\n",
    "            'n_compressed_lower': np.sum(lower_mask),\n",
    "            'n_compressed_upper': np.sum(upper_mask),\n",
    "            'original_min': np.min(values),\n",
    "            'original_max': np.max(values),\n",
    "            'compressed_min': np.min(compressed),\n",
    "            'compressed_max': np.max(compressed)\n",
    "        }\n",
    "        \n",
    "        return compressed, compression_info\n",
    "    \n",
    "    def calculate_hourly_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate hourly DAY-AHEAD price statistics with percentile compression\n",
    "        \"\"\"\n",
    "        print(\"\\nâš¡ Calculating HOURLY day-ahead price statistics...\")\n",
    "        \n",
    "        grouped = df_filtered.groupby(['month', 'day', 'hour'])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (month, day, hour), group in grouped:\n",
    "            if len(group) < 5:  # Skip if too few data points\n",
    "                continue\n",
    "            \n",
    "            prices = group['price_da'].values  # Using price_da instead of price\n",
    "            generation = group['generation_mw'].values\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month)\n",
    "            \n",
    "            # Apply percentile compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                prices, \n",
    "                self.compression_lower, \n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            # Create datetime label\n",
    "            datetime_label = f\"{self.month_names[month]}-{day:02d} {hour:02d}:00\"\n",
    "            \n",
    "            # Main statistics on COMPRESSED data for visualization\n",
    "            stats = {\n",
    "                'datetime_label': datetime_label,\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'hour': hour,\n",
    "                'month_order': month_order_map[month],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(group),\n",
    "                'avg_generation': np.mean(generation)\n",
    "            }\n",
    "            \n",
    "            # Calculate percentiles on COMPRESSED data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Also store ACTUAL percentiles for reference\n",
    "            stats['actual_mean'] = np.mean(prices)\n",
    "            stats['actual_min'] = np.min(prices)\n",
    "            stats['actual_max'] = np.max(prices)\n",
    "            stats['actual_p5'] = np.percentile(prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames and sort\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} hourly slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_daily_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate daily GENERATION-WEIGHTED day-ahead price statistics with compression\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“… Calculating DAILY generation-weighted day-ahead price statistics...\")\n",
    "        \n",
    "        # First calculate generation-weighted prices for each day\n",
    "        def calc_weighted_daily(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return pd.Series({\n",
    "                    'weighted_price_da': np.nan,\n",
    "                    'total_generation': 0,\n",
    "                    'generating_hours': 0\n",
    "                })\n",
    "            \n",
    "            gen_positive = group.loc[mask]\n",
    "            weighted_price = (gen_positive['price_da'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "            \n",
    "            return pd.Series({\n",
    "                'weighted_price_da': weighted_price,\n",
    "                'total_generation': group['generation_mw'].sum(),\n",
    "                'generating_hours': mask.sum()\n",
    "            })\n",
    "        \n",
    "        # Calculate daily aggregates for each year\n",
    "        daily_data = df_filtered.groupby(['year', 'month', 'day']).apply(calc_weighted_daily).reset_index()\n",
    "        \n",
    "        # Now calculate statistics across years for each day\n",
    "        grouped = daily_data.groupby(['month', 'day'])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (month, day), group in grouped:\n",
    "            valid_group = group[group['weighted_price_da'].notna()]\n",
    "            if len(valid_group) < 5:\n",
    "                continue\n",
    "            \n",
    "            weighted_prices = valid_group['weighted_price_da'].values\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month)\n",
    "            \n",
    "            # Apply compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                weighted_prices,\n",
    "                self.compression_lower,\n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            # Create date label\n",
    "            date_label = f\"{self.month_names[month]}-{day:02d}\"\n",
    "            \n",
    "            # Main statistics on compressed data\n",
    "            stats = {\n",
    "                'date_label': date_label,\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'month_order': month_order_map[month],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(valid_group),\n",
    "                'avg_generation_mwh': valid_group['total_generation'].mean(),\n",
    "                'avg_generating_hours': valid_group['generating_hours'].mean()\n",
    "            }\n",
    "            \n",
    "            # Percentiles on compressed data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Actual percentiles for reference\n",
    "            stats['actual_mean'] = np.mean(weighted_prices)\n",
    "            stats['actual_min'] = np.min(weighted_prices)\n",
    "            stats['actual_max'] = np.max(weighted_prices)\n",
    "            stats['actual_p5'] = np.percentile(weighted_prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(weighted_prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(weighted_prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(weighted_prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} daily slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_monthly_statistics(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Calculate monthly GENERATION-WEIGHTED day-ahead price statistics with compression\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š Calculating MONTHLY generation-weighted day-ahead price statistics...\")\n",
    "        \n",
    "        # Calculate monthly weighted prices\n",
    "        def calc_weighted_monthly(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return pd.Series({\n",
    "                    'weighted_price_da': np.nan,\n",
    "                    'total_generation': 0,\n",
    "                    'generating_hours': 0\n",
    "                })\n",
    "            \n",
    "            gen_positive = group.loc[mask]\n",
    "            weighted_price = (gen_positive['price_da'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "            \n",
    "            return pd.Series({\n",
    "                'weighted_price_da': weighted_price,\n",
    "                'total_generation': group['generation_mw'].sum(),\n",
    "                'generating_hours': mask.sum()\n",
    "            })\n",
    "        \n",
    "        # Calculate monthly aggregates for each year\n",
    "        monthly_data = df_filtered.groupby(['year', 'month']).apply(calc_weighted_monthly).reset_index()\n",
    "        \n",
    "        # Calculate statistics across years for each month\n",
    "        grouped = monthly_data.groupby('month')\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for month, group in grouped:\n",
    "            valid_group = group[group['weighted_price_da'].notna()]\n",
    "            if len(valid_group) < 5:\n",
    "                continue\n",
    "            \n",
    "            weighted_prices = valid_group['weighted_price_da'].values\n",
    "            \n",
    "            month_idx = int(month)\n",
    "            \n",
    "            # Determine the forecast year\n",
    "            forecast_year = self.get_forecast_year(month_idx)\n",
    "            \n",
    "            # Apply compression\n",
    "            compressed_prices, compression_info = self.compress_outliers(\n",
    "                weighted_prices,\n",
    "                self.compression_lower,\n",
    "                self.compression_upper\n",
    "            )\n",
    "            \n",
    "            stats = {\n",
    "                'month_name': self.month_names_full[month_idx],\n",
    "                'year': forecast_year,  # ADD YEAR\n",
    "                'month': month_idx,\n",
    "                'month_order': month_order_map[month_idx],\n",
    "                'mean': np.mean(compressed_prices),\n",
    "                'std_dev': np.std(compressed_prices),\n",
    "                'count': len(valid_group),\n",
    "                'avg_generation_mwh': valid_group['total_generation'].mean(),\n",
    "                'avg_generating_hours': valid_group['generating_hours'].mean()\n",
    "            }\n",
    "            \n",
    "            # Percentiles on compressed data\n",
    "            for p in self.full_percentiles:\n",
    "                stats[f'p{p}'] = np.percentile(compressed_prices, p)\n",
    "            \n",
    "            # Actual values\n",
    "            stats['actual_mean'] = np.mean(weighted_prices)\n",
    "            stats['actual_min'] = np.min(weighted_prices)\n",
    "            stats['actual_max'] = np.max(weighted_prices)\n",
    "            stats['actual_p5'] = np.percentile(weighted_prices, 5)\n",
    "            stats['actual_p10'] = np.percentile(weighted_prices, 10)\n",
    "            stats['actual_p90'] = np.percentile(weighted_prices, 90)\n",
    "            stats['actual_p95'] = np.percentile(weighted_prices, 95)\n",
    "            \n",
    "            results.append(stats)\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        results_df = results_df.drop('month_order', axis=1)\n",
    "        \n",
    "        print(f\"   âœ“ Calculated statistics for {len(results_df)} months\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def create_hourly_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly day-ahead price timeseries with years as columns\n",
    "        \"\"\"\n",
    "        print(\"\\nâ° Creating HOURLY day-ahead price timeseries...\")\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        df_work = df_filtered.copy()\n",
    "        \n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Pivot for day-ahead prices\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values='price_da',  # Using price_da instead of price\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} hourly slots\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_daily_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create daily GENERATION-WEIGHTED day-ahead price timeseries\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“… Creating DAILY generation-weighted day-ahead price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted daily prices\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            return (gen_positive['price_da'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_daily = df_filtered.groupby(['year', 'month', 'day']).apply(calc_weighted_price).reset_index()\n",
    "        df_daily.columns = ['year', 'month', 'day', 'weighted_price_da']\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        \n",
    "        df_daily['month_order'] = df_daily['month'].map(month_order_map)\n",
    "        \n",
    "        pivot_df = df_daily.pivot_table(\n",
    "            index=['month', 'day', 'month_order'],\n",
    "            columns='year',\n",
    "            values='weighted_price_da',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['date_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d}\",\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['date_label', 'month', 'day'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} daily slots\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_monthly_timeseries(self, df_filtered, month_order_map):\n",
    "        \"\"\"\n",
    "        Create monthly GENERATION-WEIGHTED day-ahead price timeseries\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š Creating MONTHLY generation-weighted day-ahead price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted monthly prices\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            return (gen_positive['price_da'] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_monthly = df_filtered.groupby(['year', 'month']).apply(calc_weighted_price).reset_index()\n",
    "        df_monthly.columns = ['year', 'month', 'weighted_price_da']\n",
    "        \n",
    "        # Use all available data - no year skipping\n",
    "        \n",
    "        df_monthly['month_order'] = df_monthly['month'].map(month_order_map)\n",
    "        \n",
    "        pivot_df = df_monthly.pivot_table(\n",
    "            index=['month', 'month_order'],\n",
    "            columns='year',\n",
    "            values='weighted_price_da',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        pivot_df = pivot_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        \n",
    "        pivot_df['month_name'] = pivot_df['month'].apply(lambda x: self.month_names_full[int(x)])\n",
    "        \n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        year_cols = [col for col in pivot_df.columns if isinstance(col, int)]\n",
    "        cols = ['month_name', 'month'] + sorted(year_cols)\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   âœ“ Created timeseries for {len(pivot_df)} months\")\n",
    "        print(f\"   âœ“ Including data from all {len(year_cols)} years\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def save_all_results(self, hourly_stats, daily_stats, monthly_stats, \n",
    "                        hourly_ts, daily_ts, monthly_ts, site_name):\n",
    "        \"\"\"\n",
    "        Save all files in the new structure: Renewable Portfolio LLC/{site_name}/Price_da/\n",
    "        \"\"\"\n",
    "        # Create the site-specific Price_da folder\n",
    "        price_da_path = self.base_output_path / site_name / 'Price_da'\n",
    "        price_da_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create plots folder for the site (if not already created by other scripts)\n",
    "        plots_path = self.base_output_path / site_name / 'plots'\n",
    "        plots_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save hourly statistics (CHANGED: stats -> forecast)\n",
    "        hourly_file = f\"{site_name}_price_da_hourly_forecast.csv\"\n",
    "        hourly_path = price_da_path / hourly_file\n",
    "        \n",
    "        cols_hourly = ['datetime_label', 'year', 'month', 'day', 'hour', 'mean', 'std_dev'] + \\\n",
    "                     [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                     ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10', \n",
    "                      'actual_p90', 'actual_p95', 'count', 'avg_generation']\n",
    "        \n",
    "        hourly_stats[cols_hourly].to_csv(hourly_path, index=False, float_format='%.3f')\n",
    "        print(f\"\\nğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{hourly_file}\")\n",
    "        \n",
    "        # Save daily statistics (CHANGED: stats -> forecast)\n",
    "        daily_file = f\"{site_name}_price_da_daily_forecast.csv\"\n",
    "        daily_path = price_da_path / daily_file\n",
    "        \n",
    "        cols_daily = ['date_label', 'year', 'month', 'day', 'mean', 'std_dev'] + \\\n",
    "                    [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                    ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10',\n",
    "                     'actual_p90', 'actual_p95', 'count', 'avg_generation_mwh', 'avg_generating_hours']\n",
    "        \n",
    "        daily_stats[cols_daily].to_csv(daily_path, index=False, float_format='%.3f')\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{daily_file}\")\n",
    "        \n",
    "        # Save monthly statistics (CHANGED: stats -> forecast)\n",
    "        monthly_file = f\"{site_name}_price_da_monthly_forecast.csv\"\n",
    "        monthly_path = price_da_path / monthly_file\n",
    "        \n",
    "        cols_monthly = ['month_name', 'year', 'month', 'mean', 'std_dev'] + \\\n",
    "                      [f'p{p}' for p in self.full_percentiles] + \\\n",
    "                      ['actual_mean', 'actual_min', 'actual_max', 'actual_p5', 'actual_p10',\n",
    "                       'actual_p90', 'actual_p95', 'count', 'avg_generation_mwh', 'avg_generating_hours']\n",
    "        \n",
    "        monthly_stats[cols_monthly].to_csv(monthly_path, index=False, float_format='%.3f')\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{monthly_file}\")\n",
    "        \n",
    "        # Save hourly timeseries\n",
    "        hourly_ts_file = f\"{site_name}_price_da_hourly_timeseries.csv\"\n",
    "        hourly_ts_path = price_da_path / hourly_ts_file\n",
    "        hourly_ts_save = hourly_ts.copy()\n",
    "        year_cols = [col for col in hourly_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            hourly_ts_save[col] = hourly_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        hourly_ts_save.to_csv(hourly_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{hourly_ts_file}\")\n",
    "        \n",
    "        # Save daily timeseries\n",
    "        daily_ts_file = f\"{site_name}_price_da_daily_timeseries.csv\"\n",
    "        daily_ts_path = price_da_path / daily_ts_file\n",
    "        daily_ts_save = daily_ts.copy()\n",
    "        year_cols = [col for col in daily_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            daily_ts_save[col] = daily_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        daily_ts_save.to_csv(daily_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{daily_ts_file}\")\n",
    "        \n",
    "        # Save monthly timeseries\n",
    "        monthly_ts_file = f\"{site_name}_price_da_monthly_timeseries.csv\"\n",
    "        monthly_ts_path = price_da_path / monthly_ts_file\n",
    "        monthly_ts_save = monthly_ts.copy()\n",
    "        year_cols = [col for col in monthly_ts_save.columns if isinstance(col, int)]\n",
    "        for col in year_cols:\n",
    "            monthly_ts_save[col] = monthly_ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "        monthly_ts_save.to_csv(monthly_ts_path, index=False)\n",
    "        print(f\"ğŸ’¾ Saved: Renewable Portfolio LLC/{site_name}/Price_da/{monthly_ts_file}\")\n",
    "    \n",
    "    def print_sample_results(self, hourly_stats, daily_stats):\n",
    "        \"\"\"\n",
    "        Print formatted sample results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE DAY-AHEAD RESULTS WITH COMPRESSION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Sample hourly statistics\n",
    "        print(\"\\nâš¡ HOURLY DAY-AHEAD PRICE STATISTICS SAMPLE:\")\n",
    "        if not hourly_stats.empty:\n",
    "            mid_month = hourly_stats['month'].min()\n",
    "            sample = hourly_stats[(hourly_stats['month'] == mid_month) & \n",
    "                                (hourly_stats['day'] == 15) & \n",
    "                                (hourly_stats['hour'] == 12)]\n",
    "            \n",
    "            if not sample.empty:\n",
    "                row = sample.iloc[0]\n",
    "                \n",
    "                print(f\"\\n   {row['datetime_label']} (Year: {row['year']}):\")\n",
    "                print(f\"   Original range: ${row['actual_min']:.2f} to ${row['actual_max']:.2f}\")\n",
    "                print(f\"   Mean: ${row['mean']:.2f}, P10-P90: ${row['p10']:.2f}-${row['p90']:.2f}\")\n",
    "                print(f\"   (Statistics based on compressed values)\")\n",
    "        \n",
    "        # Sample daily statistics\n",
    "        print(\"\\nğŸ“… DAILY WEIGHTED DAY-AHEAD PRICE STATISTICS SAMPLE:\")\n",
    "        if not daily_stats.empty:\n",
    "            mid_month = daily_stats['month'].min()\n",
    "            sample = daily_stats[(daily_stats['month'] == mid_month) & (daily_stats['day'] == 15)]\n",
    "            \n",
    "            if not sample.empty:\n",
    "                row = sample.iloc[0]\n",
    "                print(f\"\\n   {row['date_label']} (Year: {row['year']}):\")\n",
    "                print(f\"   Weighted avg: ${row['mean']:.2f}, P10-P90: ${row['p10']:.2f}-${row['p90']:.2f}\")\n",
    "                print(f\"   Based on {row['avg_generating_hours']:.1f} generating hours/day\")\n",
    "    \n",
    "    def process_single_site(self, site_name, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Process a single site with given month range\n",
    "        \"\"\"\n",
    "        # Create month order mapping\n",
    "        month_order_map = self.create_month_order_map(start_month, end_month)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {site_name}\")\n",
    "        \n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        num_months = len(months_in_range)\n",
    "        \n",
    "        if start_month <= end_month:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} ({num_months} months)\")\n",
    "        else:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} (year-wrapping, {num_months} months)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Use the mapping to get the actual filename\n",
    "        actual_filename = self.site_file_map.get(site_name)\n",
    "        if actual_filename:\n",
    "            file_path = self.data_path / actual_filename\n",
    "        else:\n",
    "            # Fallback - try the standard naming convention\n",
    "            file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "            \n",
    "        print(f\"\\nğŸ“ Loading data from: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            \n",
    "            # Extract day of month from datetime since it's not in the columns\n",
    "            df['day'] = df['datetime'].dt.day\n",
    "            \n",
    "            # Ensure all columns are integers\n",
    "            df['year'] = df['year'].astype(int)\n",
    "            df['month'] = df['month'].astype(int)\n",
    "            df['hour'] = df['hour'].astype(int)\n",
    "            \n",
    "            # Filter for selected months\n",
    "            df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "            \n",
    "            # Get data summary\n",
    "            years_available = sorted(df_filtered['year'].unique())\n",
    "            print(f\"\\nğŸ“Š Data summary:\")\n",
    "            print(f\"   Years available: {years_available[0]} to {years_available[-1]} ({len(years_available)} years)\")\n",
    "            print(f\"   Total data points: {len(df_filtered):,}\")\n",
    "            print(f\"   Day-ahead price range: ${df_filtered['price_da'].min():.2f} to ${df_filtered['price_da'].max():.2f}\")\n",
    "            print(f\"   Negative day-ahead price hours: {(df_filtered['price_da'] < 0).sum()} ({(df_filtered['price_da'] < 0).sum()/len(df_filtered)*100:.1f}%)\")\n",
    "            \n",
    "            # Updated note about year-wrapping\n",
    "            if start_month > end_month:\n",
    "                print(f\"\\n   â„¹ï¸  Note: Year-wrapping range detected!\")\n",
    "                print(f\"   First year ({years_available[0]}) and last year ({years_available[-1]}) may have partial data\")\n",
    "                print(f\"   All available data will be included in the timeseries files\")\n",
    "            \n",
    "            # Calculate statistics at all three levels\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"DAY-AHEAD PRICE DISTRIBUTION STATISTICS\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            hourly_stats = self.calculate_hourly_statistics(df_filtered, month_order_map)\n",
    "            daily_stats = self.calculate_daily_statistics(df_filtered, month_order_map)\n",
    "            monthly_stats = self.calculate_monthly_statistics(df_filtered, month_order_map)\n",
    "            \n",
    "            # Create timeseries\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"DAY-AHEAD PRICE TIMESERIES GENERATION\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            hourly_ts = self.create_hourly_timeseries(df_filtered, month_order_map)\n",
    "            daily_ts = self.create_daily_timeseries(df_filtered, month_order_map)\n",
    "            monthly_ts = self.create_monthly_timeseries(df_filtered, month_order_map)\n",
    "            \n",
    "            # Print samples\n",
    "            self.print_sample_results(hourly_stats, daily_stats)\n",
    "            \n",
    "            # Save all results\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"SAVING RESULTS\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "            self.save_all_results(hourly_stats, daily_stats, monthly_stats,\n",
    "                                hourly_ts, daily_ts, monthly_ts, site_name)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error processing {site_name}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def run_simulation(self):\n",
    "        \"\"\"\n",
    "        Main function to run the day-ahead price simulation\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ’° Day-Ahead Price Simulation with Outlier Compression\")\n",
    "        print(\"   (Handles extreme day-ahead prices elegantly)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            return\n",
    "        \n",
    "        # Get automatic month range\n",
    "        start_month, end_month = self.get_automatic_month_range()\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"ğŸš€ PROCESSING ALL SITES\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(self.available_sites, 1):\n",
    "                print(f\"\\n[{i}/{len(self.available_sites)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name, start_month, end_month):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"âœ¨ ALL SITES PROCESSING COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\nğŸ“Š Summary:\")\n",
    "            print(f\"   âœ… Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   âŒ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "            print(f\"\\nğŸ“ Files saved in: Renewable Portfolio LLC/[site_name]/Price_da/\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection, start_month, end_month):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"âœ¨ DAY-AHEAD PRICE SIMULATION COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\nAnalysis created for {site_selection}\")\n",
    "                \n",
    "                print(f\"12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "                \n",
    "                print(f\"\\nğŸ“ Files saved in:\")\n",
    "                print(f\"   Renewable Portfolio LLC/{site_selection}/Price_da/\")\n",
    "                print(\"     â€¢ Hourly/Daily/Monthly day-ahead price statistics (with year column)\")\n",
    "                print(\"     â€¢ Hourly/Daily/Monthly day-ahead price timeseries\")\n",
    "                print(f\"   Renewable Portfolio LLC/{site_selection}/plots/\")\n",
    "                print(\"     â€¢ (Ready for future visualizations)\")\n",
    "                \n",
    "                print(\"\\nğŸ’¡ Key features:\")\n",
    "                print(\"   â€¢ Outliers compressed logarithmically (P10-P90)\")\n",
    "                print(\"   â€¢ Full P1-P99 percentiles available\")\n",
    "                print(\"   â€¢ Actual values tracked for reference\")\n",
    "                print(\"   â€¢ Daily and Monthly use generation-weighted prices\")\n",
    "        \n",
    "        # Ask if user wants to create another simulation\n",
    "        another = input(\"\\nğŸ”„ Create another day-ahead price simulation? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_simulation()\n",
    "\n",
    "# Run the simulation\n",
    "if __name__ == \"__main__\":\n",
    "    simulator = PriceDayAheadSimulation()\n",
    "    simulator.run_simulation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
